

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>train &mdash; ArgueFlow  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            ArgueFlow
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">argueflow package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../modules.html#train.set_random_seed"><code class="docutils literal notranslate"><span class="pre">set_random_seed()</span></code></a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ArgueFlow</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Module code</a></li>
      <li class="breadcrumb-item active">train</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for train</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This module handles model training, validation, and fold-wise setup for the ArgueFlow pipeline.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># import logging</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>

<span class="c1"># import time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># import pandas as pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>


<span class="c1"># from imp import reload</span>


<span class="c1"># For SWA</span>
<span class="c1"># from transformers import (</span>
<span class="c1">#     AutoConfig,</span>
<span class="c1">#     AutoTokenizer,</span>
<span class="c1"># )</span>


<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;CUDA_LAUNCH_BLOCKING&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;1&#39;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;TOKENIZERS_PARALLELISM&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;true&#39;</span>

<span class="c1"># &quot;&quot;&quot;# Initial configuration&quot;&quot;&quot;</span>


<span class="c1"># class Config:</span>
<span class="c1">#     # General settings</span>
<span class="c1">#     competition_name = &#39;FeedbackPrize2&#39;</span>
<span class="c1">#     env = &#39;local&#39;</span>
<span class="c1">#     seed = 1</span>
<span class="c1">#     mode = &#39;train&#39;  # &#39;train&#39;, &#39;valid&#39;</span>
<span class="c1">#     debug = False</span>
<span class="c1">#     model_name = &#39;v1a&#39;</span>
<span class="c1">#     processed_data = (</span>
<span class="c1">#         True  # Set to True if the train_df is processed and added with the target (rank)</span>
<span class="c1">#     )</span>
<span class="c1">#     use_tqdm = True</span>
<span class="c1">#     # For model</span>
<span class="c1">#     backbone = &#39;microsoft/deberta-v3-large&#39;</span>
<span class="c1">#     tokenizer = AutoTokenizer.from_pretrained(backbone)</span>
<span class="c1">#     config = AutoConfig.from_pretrained(backbone)</span>
<span class="c1">#     config.output_hidden_states = True</span>
<span class="c1">#     config.hidden_dropout_prob = 0.0</span>
<span class="c1">#     config.attention_probs_dropout_prob = 0.0</span>
<span class="c1">#     # Add new token</span>
<span class="c1">#     cls_token = &#39;[FP2]&#39;</span>
<span class="c1">#     special_tokens_dict = {&#39;additional_special_tokens&#39;: [cls_token]}</span>
<span class="c1">#     tokenizer.add_special_tokens(special_tokens_dict)</span>
<span class="c1">#     cls_token_id = tokenizer(cls_token)[&#39;input_ids&#39;][1]</span>
<span class="c1">#     # For data</span>
<span class="c1">#     discourse_type_map = {</span>
<span class="c1">#         &#39;Lead&#39;: 0,</span>
<span class="c1">#         &#39;Position&#39;: 1,</span>
<span class="c1">#         &#39;Claim&#39;: 2,</span>
<span class="c1">#         &#39;Counterclaim&#39;: 3,</span>
<span class="c1">#         &#39;Rebuttal&#39;: 4,</span>
<span class="c1">#         &#39;Evidence&#39;: 5,</span>
<span class="c1">#         &#39;Concluding Statement&#39;: 6,</span>
<span class="c1">#     }</span>
<span class="c1">#     label_map = {</span>
<span class="c1">#         &#39;Ineffective&#39;: 0,</span>
<span class="c1">#         &#39;Adequate&#39;: 1,</span>
<span class="c1">#         &#39;Effective&#39;: 2,</span>
<span class="c1">#         &#39;None&#39;: -100,</span>
<span class="c1">#     }</span>
<span class="c1">#     training_folds = [0]</span>
<span class="c1">#     max_len = 1024</span>
<span class="c1">#     batch_size = 4</span>
<span class="c1">#     num_workers = os.cpu_count()</span>
<span class="c1">#     # For training</span>
<span class="c1">#     apex = True</span>
<span class="c1">#     gradient_checkpointing = True</span>
<span class="c1">#     device = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)</span>
<span class="c1">#     nepochs = 5</span>
<span class="c1">#     start_val_epoch = 2</span>
<span class="c1">#     val_check_interval = 0.1</span>
<span class="c1">#     gradient_accumulation_steps = 1.0</span>
<span class="c1">#     max_grad_norm = 1000</span>
<span class="c1">#     label_smoothing = 0.03</span>
<span class="c1">#     # For SWA</span>
<span class="c1">#     use_swa = False</span>
<span class="c1">#     if use_swa:</span>
<span class="c1">#         start_swa_epoch = 2</span>
<span class="c1">#         swa_lr = 5e-6</span>
<span class="c1">#         swa_anneal_strategy = &#39;cos&#39;</span>
<span class="c1">#         swa_anneal_epochs = 1</span>
<span class="c1">#     else:</span>
<span class="c1">#         start_swa_epoch = nepochs + 1</span>
<span class="c1">#     # For AWP</span>
<span class="c1">#     use_awp = True</span>
<span class="c1">#     if use_awp:</span>
<span class="c1">#         start_awp_epoch = 2</span>
<span class="c1">#         adv_lr = 1e-5</span>
<span class="c1">#         adv_eps = 1e-3</span>
<span class="c1">#         adv_step = 1</span>
<span class="c1">#     else:</span>
<span class="c1">#         start_awp_epoch = nepochs + 1</span>
<span class="c1">#     # Optimizer</span>
<span class="c1">#     lr = 1e-5</span>
<span class="c1">#     weight_decay = 1e-2</span>
<span class="c1">#     encoder_lr = 1e-5</span>
<span class="c1">#     decoder_lr = 1e-5</span>
<span class="c1">#     min_lr = 1e-6</span>
<span class="c1">#     eps = 1e-6</span>
<span class="c1">#     betas = (0.9, 0.999)</span>
<span class="c1">#     # Scheduler</span>
<span class="c1">#     scheduler_type = &#39;cosine&#39;  # &#39;linear&#39;, &#39;cosine&#39;</span>
<span class="c1">#     if scheduler_type == &#39;cosine&#39;:</span>
<span class="c1">#         num_cycles = 0.5</span>
<span class="c1">#     num_warmup_steps = 100</span>
<span class="c1">#     batch_scheduler = True</span>
<span class="c1">#     # Directories</span>
<span class="c1">#     if env == &#39;colab&#39;:</span>
<span class="c1">#         comp_data_dir = (</span>
<span class="c1">#             f&#39;/content/drive/My Drive/Kaggle competitions/{competition_name}/comp_data&#39;</span>
<span class="c1">#         )</span>
<span class="c1">#         extra_data_dir = (</span>
<span class="c1">#             f&#39;/content/drive/My Drive/Kaggle competitions/{competition_name}/extra_data&#39;</span>
<span class="c1">#         )</span>
<span class="c1">#         model_dir = (</span>
<span class="c1">#             f&#39;/content/drive/My Drive/Kaggle competitions/{competition_name}/model&#39;</span>
<span class="c1">#         )</span>
<span class="c1">#         os.makedirs(</span>
<span class="c1">#             os.path.join(</span>
<span class="c1">#                 model_dir, model_name.split(&#39;_&#39;)[0][:-1], model_name.split(&#39;_&#39;)[0][-1]</span>
<span class="c1">#             ),</span>
<span class="c1">#             exist_ok=True,</span>
<span class="c1">#         )</span>
<span class="c1">#         old_comp_data_dir = (</span>
<span class="c1">#             f&#39;/content/drive/My Drive/Kaggle competitions/{competition_name[:-1]}/data&#39;</span>
<span class="c1">#         )</span>
<span class="c1">#     elif env == &#39;kaggle&#39;:</span>
<span class="c1">#         comp_data_dir = ...</span>
<span class="c1">#         extra_data_dir = ...</span>
<span class="c1">#         model_dir = ...</span>
<span class="c1">#     elif env == &#39;vastai&#39;:</span>
<span class="c1">#         comp_data_dir = &#39;data&#39;</span>
<span class="c1">#         extra_data_dir = &#39;data&#39;</span>
<span class="c1">#         model_dir = &#39;model&#39;</span>
<span class="c1">#         os.makedirs(</span>
<span class="c1">#             os.path.join(</span>
<span class="c1">#                 model_dir, model_name.split(&#39;_&#39;)[0][:-1], model_name.split(&#39;_&#39;)[0][-1]</span>
<span class="c1">#             ),</span>
<span class="c1">#             exist_ok=True,</span>
<span class="c1">#         )</span>
<span class="c1">#     elif env == &#39;local&#39;:</span>
<span class="c1">#         comp_data_dir = &#39;data&#39;</span>
<span class="c1">#         extra_data_dir = &#39;ext_data&#39;</span>
<span class="c1">#         model_dir = &#39;model&#39;</span>
<span class="c1">#         os.makedirs(</span>
<span class="c1">#             os.path.join(</span>
<span class="c1">#                 model_dir, model_name.split(&#39;_&#39;)[0][:-1], model_name.split(&#39;_&#39;)[0][-1]</span>
<span class="c1">#             ),</span>
<span class="c1">#             exist_ok=True,</span>
<span class="c1">#         )</span>


<span class="c1"># cfg = Config()</span>

<span class="c1"># &quot;&quot;&quot;# Random seed&quot;&quot;&quot;</span>


<div class="viewcode-block" id="set_random_seed">
<a class="viewcode-back" href="../modules.html#train.set_random_seed">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">set_random_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sets random seeds for reproducibility across NumPy, PyTorch, and Python.</span>

<span class="sd">    Args:</span>
<span class="sd">        seed (int): The seed value to use.</span>
<span class="sd">        use_cuda (bool): Whether to apply CUDA-specific seed settings. Defaults to True.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>  <span class="c1"># cpu vars</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>  <span class="c1"># cpu  vars</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>  <span class="c1"># Python</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;PYTHONHASHSEED&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>  <span class="c1"># Python hash building</span>
    <span class="k">if</span> <span class="n">use_cuda</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>  <span class="c1"># gpu vars</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># needed</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span></div>



<span class="c1"># set_random_seed(cfg.seed)</span>

<span class="c1"># &quot;&quot;&quot;# Set-up log&quot;&quot;&quot;</span>


<span class="c1"># # reload(logging)</span>
<span class="c1"># # logging.basicConfig(</span>
<span class="c1"># #     level=logging.INFO,</span>
<span class="c1"># #     format=&#39;%(asctime)s %(message)s&#39;,</span>
<span class="c1"># #     datefmt=&#39;%H:%M:%S&#39;,</span>
<span class="c1"># #     handlers=[</span>
<span class="c1"># #         logging.FileHandler(</span>
<span class="c1"># #             f&quot;train_{cfg.model_name}_{time.strftime(&#39;%m%d_%H%M&#39;, time.localtime())}_{cfg.seed}.log&quot;</span>
<span class="c1"># #         ),</span>
<span class="c1"># #         logging.StreamHandler(),</span>
<span class="c1"># #     ],</span>
<span class="c1"># # )</span>

<span class="c1"># logging.info(</span>
<span class="c1">#     &#39;\nmodel_name: {}\n&#39;</span>
<span class="c1">#     &#39;env: {}\n&#39;</span>
<span class="c1">#     &#39;seed: {}\n&#39;</span>
<span class="c1">#     &#39;training_folds: {}\n&#39;</span>
<span class="c1">#     &#39;max_len: {}\n&#39;</span>
<span class="c1">#     &#39;batch_size: {}\n&#39;</span>
<span class="c1">#     &#39;num_workers: {}\n&#39;</span>
<span class="c1">#     &#39;nepochs: {}\n&#39;</span>
<span class="c1">#     &#39;lr: {}\n&#39;</span>
<span class="c1">#     &#39;weight_decay: {}\n&#39;</span>
<span class="c1">#     &#39;gradient_accumulation_steps: {}&#39;.format(</span>
<span class="c1">#         cfg.model_name,</span>
<span class="c1">#         cfg.env,</span>
<span class="c1">#         cfg.seed,</span>
<span class="c1">#         cfg.training_folds,</span>
<span class="c1">#         cfg.max_len,</span>
<span class="c1">#         cfg.batch_size,</span>
<span class="c1">#         cfg.num_workers,</span>
<span class="c1">#         cfg.nepochs,</span>
<span class="c1">#         cfg.lr,</span>
<span class="c1">#         cfg.weight_decay,</span>
<span class="c1">#         cfg.gradient_accumulation_steps,</span>
<span class="c1">#     )</span>
<span class="c1"># )</span>

<span class="c1"># &quot;&quot;&quot;# Import data</span>

<span class="c1"># * Train data</span>
<span class="c1"># &quot;&quot;&quot;</span>

<span class="c1"># if cfg.processed_data:</span>
<span class="c1">#     train = pd.read_csv(os.path.join(cfg.extra_data_dir, f&#39;train_seed_{cfg.seed}.csv&#39;))</span>
<span class="c1"># else:</span>
<span class="c1">#     train = pd.read_csv(os.path.join(cfg.comp_data_dir, &#39;train.csv&#39;))</span>
<span class="c1"># train</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Vladimir Smirnov.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>